
---
title: "Automate_data_splits_oversampling_v.2"
output:
  html_document:
    toc: true
---


```{r}
%md
Data ingestion
```


```{r}
%md
Original Device variables
```


```{r}
install.packages("SparkR")
library(SparkR)
sparkR.session()

# Define the file path
training_file_path <- "dbfs:/FileStore/tables/ecom_user_data/customer_propensity_training_sample.csv"
testing_file_path <- "dbfs:/FileStore/tables/ecom_user_data/customer_propensity_testing_sample.csv"

# Read the CSV file into a Spark DataFrame
kaggle_training_data_df <- read.df(training_file_path, source = "csv", header = "true", inferSchema = "true")
kaggle_testing_data_df <- read.df(testing_file_path, source = "csv", header = "true", inferSchema = "true")

# Combine datasets
kaggle_total_data <- rbind(kaggle_training_data_df, kaggle_testing_data_df)

# Bring the data from Spark into R memory - only required for SparkR
original_kaggle_total_data <- collect(kaggle_total_data)

# Remove UserID
original_kaggle_total_data <- original_kaggle_total_data[,-1]

# Make sure ordered is a factor
original_kaggle_total_data$ordered <- as.factor(original_kaggle_total_data$ordered)

# Check the structure
str(original_kaggle_total_data) 
```


```{r}
library(dplyr)
original_kaggle_total_data %>% filter(device_mobile == 1) %>% count()
```


```{r}
original_kaggle_total_data %>% filter(device_computer == 1) %>% count()
```


```{r}
original_kaggle_total_data %>% filter(device_tablet == 1) %>% count()
```


```{r}
%md
Transformed Device variable
```


```{r}
library(SparkR)
sparkR.session()


# Define the file path
training_file_path <- "dbfs:/FileStore/tables/ecom_user_data/customer_propensity_training_sample.csv"
testing_file_path <- "dbfs:/FileStore/tables/ecom_user_data/customer_propensity_testing_sample.csv"

# Read the CSV file into a Spark DataFrame
kaggle_training_data_df <- read.df(training_file_path, source = "csv", header = "true", inferSchema = "true")
kaggle_testing_data_df <- read.df(testing_file_path, source = "csv", header = "true", inferSchema = "true")

# Combine datasets
kaggle_total_data <- rbind(kaggle_training_data_df, kaggle_testing_data_df)

# Bring the data from Spark into R memory - only required for SparkR
kaggle_total_data <- collect(kaggle_total_data)

# Refactor device type variable to be categorical
kaggle_total_data$device_type <- ifelse(
  kaggle_total_data$device_mobile == 1, "mobile",
  ifelse(
    kaggle_total_data$device_computer == 1, "computer",
    "tablet"
  )
)

# Then make sure it's a factor - factor() is similar to as.factor()
kaggle_total_data$device_type <- factor(
  kaggle_total_data$device_type,
  levels = c("mobile", "computer", "tablet")
)

# exlucde UserID
new_kaggle_total_data <- kaggle_total_data[,-c(1, 20, 21, 22)]
# str(kaggle_total_data)
str(new_kaggle_total_data)
```


```{r}
%md
Dropped device variable
```


```{r}
dropped_device_kaggle_total_data <- kaggle_total_data[,c(-1, -19)]
str(dropped_device_kaggle_total_data)
```


```{r}
%md
Define data
```


```{r}
prepare_splits_original_kaggle_total_data <- function(seed = 1234, target = "ordered") {
  prepare_named_splits(original_kaggle_total_data, target = target, seed = seed)
}

prepare_splits_new_kaggle_total_data <- function(seed = 1234, target = "ordered") {
  prepare_named_splits(new_kaggle_total_data, target = target, seed = seed)
}

prepare_splits_dropped_device_kaggle_data <- function(seed = 1234, target = "ordered") {
  prepare_named_splits(dropped_device_kaggle, target = target, seed = seed)
}
```


```{r}
library(caret)
library(dplyr)

prepare_named_splits <- function(data, 
                                 data_prefix,      # e.g., "original_kaggle_total_data"
                                 target = "ordered", 
                                 seed = 1234) {
  set.seed(seed)
  data[[target]] <- as.factor(data[[target]])

  split_defs <- list("50" = 0.5, "60" = 0.6, "70" = 0.7, "80" = 0.8)

  for (split_name in names(split_defs)) {
    train_frac <- split_defs[[split_name]]
    test_frac <- 1 - train_frac
    test_name <- as.character(round(test_frac * 100))

    train_index <- createDataPartition(data[[target]], p = train_frac, list = FALSE)
    train_df <- data[train_index, ]
    test_df  <- data[-train_index, ]

    ctrl <- trainControl(method = "none", sampling = "up")

    # Construct persistent names with prefix
    train_var <- paste0(data_prefix, "_train_", split_name)
    test_var  <- paste0(data_prefix, "_test_", test_name)
    ctrl_var  <- paste0(data_prefix, "_ctrl_", split_name)

    assign(train_var, train_df, envir = .GlobalEnv)
    assign(test_var, test_df, envir = .GlobalEnv)
    assign(ctrl_var, ctrl, envir = .GlobalEnv)

    message("Created: ", train_var, ", ", test_var, ", ", ctrl_var)
  }
}

```


```{r}
# For original_kaggle_total_data
prepare_named_splits(original_kaggle_total_data, data_prefix = "original_kaggle_total_data")

# For new_kaggle_total_data
prepare_named_splits(new_kaggle_total_data, data_prefix = "new_kaggle_total_data")

# For dropped_device_kaggle_total_data
prepare_named_splits(dropped_device_kaggle_total_data, data_prefix = "dropped_device_kaggle_total_data")

```


```{r}
%md
Example with oversampling
```


```{r}

# Train a GLM model on the 70-30 split
model_glm <- train(
  ordered ~ ., 
  data = original_kaggle_total_data_train_50,                # Training data (oversampling happens inside)
  method = "glm", 
  family = "binomial",            # GLM for binary classification
  trControl = original_kaggle_total_data_ctrl_50             # TrainControl with oversampling
)

# Predict with the trained GLM model
preds <- predict(model_glm, newdata = original_kaggle_total_data_test_50)

# Evaluate performance
confusionMatrix(preds, original_kaggle_total_data_test_50$ordered)

```
